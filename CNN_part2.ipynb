{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://susanqq.github.io/UTKFace/\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "data_path = '/Users/daniehao/Desktop/facedata'\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    age_group=[]\n",
    "    count0 = 0\n",
    "    count2 = 0\n",
    "    count1 = 0\n",
    "    #countfile = 0\n",
    "    female = {'0':0, '1':0, '2':0}\n",
    "    male = {'0':0, '1':0, '2':0}\n",
    "    for filename in folder:\n",
    "        #if countfile>1000:\n",
    "            #break\n",
    "        #countfile+=1\n",
    "        img = image = face_recognition.load_image_file(filename)\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        try:\n",
    "            a,b,c,d=face_locations[0]\n",
    "            crop_img = img[a:c, d:b]\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "        filename = filename.split('_')\n",
    "        temp = filename[0]\n",
    "        temp = temp.split('/')\n",
    "        try:\n",
    "            age = int(temp[-1])\n",
    "            gender_index = int(filename[1])\n",
    "        except:\n",
    "            continue\n",
    "        if crop_img is not None:\n",
    "            #crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "            crop_img =cv2.resize(crop_img,(224,224))\n",
    "            if age<=15 and count0 <= 3500:\n",
    "                count0 += 1\n",
    "                age_group += [0]\n",
    "                images.append(crop_img)\n",
    "                if gender_index == 0:\n",
    "                    male['0'] += 1\n",
    "                else:\n",
    "                    female['0'] += 1\n",
    "            elif age > 45 and count1 <= 3500:\n",
    "                count1 += 1\n",
    "                age_group+=[2]\n",
    "                images.append(crop_img)\n",
    "                if gender_index == 0:\n",
    "                    male['2'] += 1\n",
    "                else:\n",
    "                    female['2'] += 1\n",
    "            elif age > 15 and age <= 45 and count2 <= 3500:\n",
    "                count2 += 1\n",
    "                age_group += [1]\n",
    "                images.append(crop_img)\n",
    "                if gender_index == 0:\n",
    "                    male['1'] += 1\n",
    "                else:\n",
    "                    female['1'] += 1\n",
    "    return images,age_group,female,male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "dir_name=sys.argv[1]\n",
    "files = []\n",
    "img_path = []\n",
    "for filename in os.listdir(data_path):\n",
    "    files.append(filename)\n",
    "# shuffle list\n",
    "random.shuffle(files)\n",
    "for item in files:\n",
    "    img_path.append(os.path.join(data_path,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data, ages, female_count, male_count=load_images_from_folder(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1866, '1': 1819, '2': 1273}\n"
     ]
    }
   ],
   "source": [
    "print(female_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1635, '1': 1682, '2': 2228}\n"
     ]
    }
   ],
   "source": [
    "print(male_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "labels = ['0-15', '16-45', '46-116']\n",
    "men_count = [1630, 1701, 2255]\n",
    "women_count = [1871, 1800, 1246]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_count, width, label='Male')\n",
    "rects2 = ax.bar(x + width/2, women_count, width, label='Female')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('count')\n",
    "ax.set_xlabel('Age Group')\n",
    "ax.set_title('Distribution by age group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10503, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = np.array(face_data)\n",
    "ages = np.array(ages)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(ages)\n",
    "plt.bar(c.keys(), c.values())\n",
    "plt.xticks(np.arange(3),['0-15','16-45','46-116'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Age group distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7877\n",
      "2626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(img_data, ages, test_size=0.25)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "y_train = label_binarize(y_train, classes=[0, 1, 2])\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2626, 224, 224, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7877, 224, 224, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(img_data, ages, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
    "import time\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# Based on VGG16 architecture -> old paper(2015)\n",
    "vggface = VGGFace(model='vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# Convolution Features\n",
    "vgg_features = VGGFace(include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "#custom parameters\n",
    "nb_class = 3\n",
    "hidden_dim = 128\n",
    "\n",
    "vgg_model = VGGFace(include_top=False, input_shape=(224,224,3))\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/daniehao/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "7877/7877 [==============================] - 4993s 634ms/step - loss: 0.6531 - acc: 0.7354\n",
      "Epoch 2/10\n",
      "7877/7877 [==============================] - 4940s 627ms/step - loss: 0.3235 - acc: 0.8728\n",
      "Epoch 3/10\n",
      "7877/7877 [==============================] - 4929s 626ms/step - loss: 0.2601 - acc: 0.8979\n",
      "Epoch 4/10\n",
      "7877/7877 [==============================] - 4929s 626ms/step - loss: 0.2478 - acc: 0.9116\n",
      "Epoch 5/10\n",
      "7877/7877 [==============================] - 4931s 626ms/step - loss: 0.1666 - acc: 0.9391\n",
      "Epoch 6/10\n",
      "7877/7877 [==============================] - 4948s 628ms/step - loss: 0.1171 - acc: 0.9581\n",
      "Epoch 7/10\n",
      "7877/7877 [==============================] - 4948s 628ms/step - loss: 0.1035 - acc: 0.9636\n",
      "Epoch 8/10\n",
      "7877/7877 [==============================] - 4963s 630ms/step - loss: 0.0716 - acc: 0.9769\n",
      "Epoch 9/10\n",
      "7877/7877 [==============================] - 4984s 633ms/step - loss: 0.0605 - acc: 0.9824\n",
      "Epoch 10/10\n",
      "7877/7877 [==============================] - 5003s 635ms/step - loss: 0.0513 - acc: 0.9874\n",
      "2626/2626 [==============================] - 780s 297ms/step\n",
      "\n",
      "Network's test loss and accuracy: [0.4832101792942676, 0.8861386138613861]\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
    "history = custom_vgg_model.fit(X_train, y_train, batch_size = 64, epochs = 10)\n",
    "score = custom_vgg_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nNetwork's test loss and accuracy: \" + format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network's train loss and accuracy: [0.006711815388158382, 0.9987304811476451]\n"
     ]
    }
   ],
   "source": [
    "score = custom_vgg_model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"\\nNetwork's train loss and accuracy: \" + format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
