{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://susanqq.github.io/UTKFace/\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "data_path = './facedata'\n",
    "\n",
    "#[age]_[gender]_[race]_[date&time].jpg\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    age_group=[]\n",
    "    count0 = 0\n",
    "    count2 = 0\n",
    "    count1 = 0\n",
    "    female = {'0':0, '1':0, '2':0}\n",
    "    male = {'0':0, '1':0, '2':0}\n",
    "    for filename in folder:\n",
    "        img = cv2.imread(filename)\n",
    "        filename = filename.split('_')\n",
    "        temp = filename[0]\n",
    "        temp = temp.split('/')\n",
    "        try:\n",
    "            age = int(temp[-1])\n",
    "            gender_index = int(filename[1])\n",
    "            #race_index = int(filename[2])\n",
    "        except:\n",
    "            continue\n",
    "        if img is not None:\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img =cv2.resize(img,(224,224))\n",
    "            if age<=15 and count0 <= 3500:\n",
    "                count0 += 1\n",
    "                age_group += [0]\n",
    "                images.append(img)\n",
    "                if gender_index == 0:\n",
    "                    male['0'] += 1\n",
    "                else:\n",
    "                    female['0'] += 1\n",
    "            elif age > 45 and count1 <= 3500:\n",
    "                count1 += 1\n",
    "                age_group+=[2]\n",
    "                images.append(img)\n",
    "                if gender_index == 0:\n",
    "                    male['2'] += 1\n",
    "                else:\n",
    "                    female['2'] += 1\n",
    "            elif age > 15 and age <= 45 and count2 <= 3500:\n",
    "                count2 += 1\n",
    "                age_group += [1]\n",
    "                images.append(img)\n",
    "                if gender_index == 0:\n",
    "                    male['1'] += 1\n",
    "                else:\n",
    "                    female['1'] += 1\n",
    "    return images,age_group,female,male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-fe386c78ebd4>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-fe386c78ebd4>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    files.append(filename)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "dir_name=sys.argv[1]\n",
    "files = []\n",
    "img_path = []\n",
    "for filename in os.listdir(data_path):random.shuffle(files)\n",
    "\n",
    "    files.append(filename)\n",
    "# shuffle list\n",
    "random.shuffle(files)\n",
    "for item in files:\n",
    "    img_path.append(os.path.join(data_path,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data, ages, female_count, male_count=load_images_from_folder(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10503, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = np.array(face_data)\n",
    "ages = np.array(ages)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data,ages, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 111, 111, 96)      2688      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 290400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                18585664  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 18,588,547\n",
      "Trainable params: 18,588,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model finished0.1768169403076172\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
    "import time\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "y_train = np_utils.to_categorical(y_train, 3)\n",
    "y_test = np_utils.to_categorical(y_test, 3)\n",
    "X_train = np.reshape(X_train, (7877, 224, 224, 3))\n",
    "X_test = np.reshape(X_test, (2626, 224, 224, 3))\n",
    "def init_model():\n",
    "    start_time = time.time()\n",
    "    print(\"compiling model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, kernel_size=(3,3), strides=(2, 2), padding='valid', activation = 'relu', input_shape=(224, 224,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.summary()\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = rms, metrics=['accuracy'])\n",
    "    print(\"Model finished\" + format(time.time() - start_time))\n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7877/7877 [==============================] - 159s 20ms/step - loss: 10.2195 - acc: 0.3367\n",
      "Epoch 2/20\n",
      "7877/7877 [==============================] - 152s 19ms/step - loss: 1.3585 - acc: 0.4033\n",
      "Epoch 3/20\n",
      "7877/7877 [==============================] - 147s 19ms/step - loss: 1.2059 - acc: 0.4533\n",
      "Epoch 4/20\n",
      "7877/7877 [==============================] - 130s 16ms/step - loss: 1.1869 - acc: 0.4785\n",
      "Epoch 5/20\n",
      "7877/7877 [==============================] - 138s 17ms/step - loss: 1.1609 - acc: 0.4780\n",
      "Epoch 6/20\n",
      "7877/7877 [==============================] - 143s 18ms/step - loss: 1.1845 - acc: 0.4770\n",
      "Epoch 7/20\n",
      "7877/7877 [==============================] - 129s 16ms/step - loss: 1.2039 - acc: 0.4577\n",
      "Epoch 8/20\n",
      "7877/7877 [==============================] - 141s 18ms/step - loss: 1.1499 - acc: 0.5106\n",
      "Epoch 9/20\n",
      "7877/7877 [==============================] - 155s 20ms/step - loss: 1.1659 - acc: 0.4941\n",
      "Epoch 10/20\n",
      "7877/7877 [==============================] - 150s 19ms/step - loss: 1.1470 - acc: 0.5064\n",
      "Epoch 11/20\n",
      "1024/7877 [==>...........................] - ETA: 2:06 - loss: 1.1277 - acc: 0.5518"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 512, epochs = 20)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nNetwork's test loss and accuracy: \" + format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"\\nNetwork's train loss and accuracy: \" + format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
    "import time\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "y_train = np_utils.to_categorical(y_train, 3)\n",
    "y_test = np_utils.to_categorical(y_test, 3)\n",
    "X_train = np.reshape(X_train, (7877, 224, 224, 3))\n",
    "X_test = np.reshape(X_test, (2626, 224, 224, 3))\n",
    "def init_model():\n",
    "    start_time = time.time()\n",
    "    print(\"compiling model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, kernel_size=(3,3), strides=(2, 2), padding='valid', activation = 'relu', input_shape=(224, 224,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(96, kernel_size=(3,3), padding='same', activation = 'relu', input_shape=(224, 224,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation = 'relu', input_shape=(224, 224,3)))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation = 'relu', input_shape=(224, 224,3)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.summary()\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = rms, metrics=['accuracy'])\n",
    "    print(\"Model finished\" + format(time.time() - start_time))\n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 128, epochs = 30)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nNetwork's test loss and accuracy: \" + format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"\\nNetwork's train loss and accuracy: \" + format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
